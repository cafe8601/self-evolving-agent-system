# ìˆ˜ëŠ¥ ACE ì—ì´ì „íŠ¸ - í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ì„¤ê³„

ê° ì»´í¬ë„ŒíŠ¸ì˜ ì—­í• ê³¼ êµ¬í˜„ ë°©ë²•

---

## 1. Learning Memory Lane (êµìœ¡ ë„ë©”ì¸ ë©”ëª¨ë¦¬)

### íŒŒì¼: `memory/learning_memory.py`

```python
"""
Learning Memory Lane - ACE V5.2 Memory Lane í™•ì¥ (êµìœ¡ ë„ë©”ì¸)

ê¸°ë³¸ 6ê°€ì§€ + êµìœ¡ ì „ìš© 6ê°€ì§€ = ì´ 12ê°€ì§€ ë©”ëª¨ë¦¬ ìœ í˜•
"""

from enum import Enum
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
import chromadb
from chromadb.utils import embedding_functions


class MemoryType(Enum):
    """ë©”ëª¨ë¦¬ ìœ í˜• (12ê°€ì§€)"""
    # ACE V5.2 ê¸°ë³¸ (6ê°€ì§€)
    CORRECTION = "correction"              # ì‚¬ìš©ì ìˆ˜ì •
    DECISION = "decision"                  # ëª…ì‹œì  ê²°ì •
    INSIGHT = "insight"                    # ê¹¨ë‹¬ìŒ
    PATTERN = "pattern"                    # ë°˜ë³µ í–‰ë™
    GAP = "gap"                           # ì‹¤íŒ¨/ëˆ„ë½
    LEARNING = "learning"                  # ì¼ë°˜ í•™ìŠµ

    # êµìœ¡ ë„ë©”ì¸ í™•ì¥ (6ê°€ì§€)
    MASTERY = "mastery"                    # ì™„ì „ ìˆ™ë‹¬
    STRUGGLE = "struggle"                  # ì§€ì†ì  ì–´ë ¤ì›€
    CORRECTION_WRONG = "correction_wrong"  # ì˜¤ë‹µ ë¶„ì„
    INSIGHT_STRATEGY = "insight_strategy"  # í•™ìŠµ ì „ëµ
    PREFERENCE_STUDY = "preference_study"  # í•™ìŠµ ìŠ¤íƒ€ì¼
    GAP_EMOTION = "gap_emotion"            # ê°ì •ì  ì–´ë ¤ì›€


class SubjectType(Enum):
    """ê³¼ëª© ìœ í˜•"""
    KOREAN = "korean"      # êµ­ì–´
    MATH = "math"          # ìˆ˜í•™
    ENGLISH = "english"    # ì˜ì–´
    SCIENCE = "science"    # ê³¼í•™íƒêµ¬
    SOCIAL = "social"      # ì‚¬íšŒíƒêµ¬
    GENERAL = "general"    # ì¼ë°˜ (ê³¼ëª© ë¬´ê´€)


@dataclass
class LearningMemory:
    """í•™ìŠµ ë©”ëª¨ë¦¬ ì—”íŠ¸ë¦¬"""
    id: str
    task: str                      # ì›ë³¸ ì‘ì—…
    result: str                    # ê²°ê³¼
    memory_type: MemoryType        # ë©”ëª¨ë¦¬ ìœ í˜•
    subject: SubjectType           # ê³¼ëª©
    mastery_level: int            # ìˆ™ë‹¬ë„ (0-10)
    emotion: str                   # ê°ì • ìƒíƒœ
    insight: str                   # í•µì‹¬ êµí›ˆ
    timestamp: datetime
    confidence: float = 0.8        # ì‹ ë¢°ë„
    urgency: float = 0.0          # ê¸´ê¸‰ë„ (D-day ê¸°ë°˜)
    review_count: int = 0         # ë³µìŠµ íšŸìˆ˜
    easiness_factor: float = 2.5  # SM-2 ì•Œê³ ë¦¬ì¦˜ìš©
    next_review_date: Optional[datetime] = None


class LearningMemoryLane:
    """
    êµìœ¡ ë„ë©”ì¸ íŠ¹í™” Memory Lane

    Features:
    - 12ê°€ì§€ ë©”ëª¨ë¦¬ ìœ í˜• (ê¸°ë³¸ 6 + êµìœ¡ 6)
    - ê³¼ëª©ë³„ í•„í„°ë§
    - D-day ê¸°ë°˜ ê¸´ê¸‰ë„ ì¬ê³„ì‚°
    - Query-Aware Type Boosting (êµìœ¡ í‚¤ì›Œë“œ)
    - Re-Ranking with Subject Match + Urgency
    """

    # Query-Aware Type Boosting Keywords (êµìœ¡ ë„ë©”ì¸)
    TYPE_BOOST_KEYWORDS = {
        # ê¸°ë³¸ í‚¤ì›Œë“œ
        "ì‹¤ìˆ˜": [MemoryType.CORRECTION, MemoryType.CORRECTION_WRONG, MemoryType.GAP],
        "ì˜ëª»": [MemoryType.CORRECTION, MemoryType.GAP],
        "ê²°ì •": [MemoryType.DECISION],
        "íŒ¨í„´": [MemoryType.PATTERN, MemoryType.LEARNING],
        "ë°©ë²•": [MemoryType.INSIGHT_STRATEGY, MemoryType.PATTERN],
        "ë°°ì›€": [MemoryType.INSIGHT, MemoryType.LEARNING],

        # êµìœ¡ ì „ìš© í‚¤ì›Œë“œ
        "ì˜í•˜ëŠ”": [MemoryType.MASTERY],
        "ìì‹ ìˆëŠ”": [MemoryType.MASTERY],
        "ë§ˆìŠ¤í„°": [MemoryType.MASTERY],
        "ì–´ë ¤ìš´": [MemoryType.STRUGGLE, MemoryType.GAP],
        "í˜ë“ ": [MemoryType.STRUGGLE, MemoryType.GAP_EMOTION],
        "ì•½ì ": [MemoryType.STRUGGLE, MemoryType.GAP],
        "í‹€ë¦°": [MemoryType.CORRECTION_WRONG, MemoryType.GAP],
        "ì˜¤ë‹µ": [MemoryType.CORRECTION_WRONG],
        "ì „ëµ": [MemoryType.INSIGHT_STRATEGY, MemoryType.PATTERN],
        "íš¨ê³¼ì ": [MemoryType.INSIGHT_STRATEGY],
        "ì„ í˜¸": [MemoryType.PREFERENCE_STUDY],
        "ì¢‹ì•„": [MemoryType.PREFERENCE_STUDY],
        "ìŠ¤íƒ€ì¼": [MemoryType.PREFERENCE_STUDY],
        "ë¶ˆì•ˆ": [MemoryType.GAP_EMOTION],
        "ìŠ¤íŠ¸ë ˆìŠ¤": [MemoryType.GAP_EMOTION],
        "ê¸´ì¥": [MemoryType.GAP_EMOTION],
    }

    def __init__(self, db_path: str = "./data/learning_memory"):
        """ì´ˆê¸°í™”"""
        self.client = chromadb.PersistentClient(path=db_path)
        self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()

        # Collection ìƒì„±
        self.collection = self.client.get_or_create_collection(
            name="learning_memory_lane",
            embedding_function=self.embedding_fn,
            metadata={"description": "Education-specific Memory Lane with 12 types"}
        )

        print(f"ğŸ§  [LearningMemoryLane] Initialized with {self.collection.count()} memories")

    def store(
        self,
        task: str,
        result: str,
        memory_type: MemoryType,
        subject: SubjectType,
        mastery_level: int,
        emotion: str,
        insight: str,
        confidence: float = 0.8,
        days_until_exam: int = 100
    ) -> str:
        """
        ë©”ëª¨ë¦¬ ì €ì¥ (Type-Aware)

        Args:
            task: í•™ìŠµ ì‘ì—…
            result: ê²°ê³¼
            memory_type: ë©”ëª¨ë¦¬ ìœ í˜• (12ê°€ì§€ ì¤‘ 1ê°œ)
            subject: ê³¼ëª©
            mastery_level: ìˆ™ë‹¬ë„ (0-10)
            emotion: ê°ì • ìƒíƒœ
            insight: í•µì‹¬ êµí›ˆ
            confidence: ì‹ ë¢°ë„
            days_until_exam: D-day (ê¸´ê¸‰ë„ ê³„ì‚°ìš©)

        Returns:
            memory_id: ì €ì¥ëœ ë©”ëª¨ë¦¬ ID
        """
        # ê¸´ê¸‰ë„ ê³„ì‚° (D-day ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ìŒ)
        urgency = 1.0 - (days_until_exam / 100.0)
        urgency = max(0.0, min(1.0, urgency))  # 0.0 ~ 1.0

        # ë©”ëª¨ë¦¬ ID ìƒì„±
        memory_id = f"{subject.value}_{memory_type.value}_{datetime.now().timestamp()}"

        # ë©”íƒ€ë°ì´í„°
        metadata = {
            "memory_type": memory_type.value,
            "subject": subject.value,
            "mastery_level": mastery_level,
            "emotion": emotion,
            "confidence": confidence,
            "urgency": urgency,
            "timestamp": datetime.now().isoformat(),
        }

        # ChromaDBì— ì €ì¥
        self.collection.add(
            ids=[memory_id],
            documents=[f"Task: {task}\nResult: {result}\nInsight: {insight}"],
            metadatas=[metadata]
        )

        print(f"ğŸ’¾ [Memory] Stored: {memory_type.value} ({subject.value}, mastery={mastery_level})")
        return memory_id

    def retrieve_context(
        self,
        query: str,
        subject: Optional[SubjectType] = None,
        top_k: int = 5,
        days_until_exam: int = 100
    ) -> List[Dict]:
        """
        ì¿¼ë¦¬ ê¸°ë°˜ ë©”ëª¨ë¦¬ ê²€ìƒ‰ (Query-Aware + Re-Ranking)

        Re-Ranking Formula:
        Final Score = (Vector Similarity Ã— 0.45)
                    + (Recency Ã— 0.10)
                    + (Confidence Ã— 0.10)
                    + (Type Boost Ã— 0.15)
                    + (Subject Match Ã— 0.10)
                    + (Urgency Ã— 0.10)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            subject: í•„í„°ë§í•  ê³¼ëª© (Noneì´ë©´ ì „ì²´)
            top_k: ë°˜í™˜í•  ë©”ëª¨ë¦¬ ìˆ˜
            days_until_exam: í˜„ì¬ D-day (ê¸´ê¸‰ë„ ì¬ê³„ì‚°ìš©)

        Returns:
            memories: Re-Rankingëœ ë©”ëª¨ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        # 1. ChromaDB ë²¡í„° ê²€ìƒ‰
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k * 3,  # Re-Rankingì„ ìœ„í•´ ë” ë§ì´ ê²€ìƒ‰
            where={"subject": subject.value} if subject else None
        )

        if not results['ids'][0]:
            return []

        # 2. Type Boost ê³„ì‚°
        boosted_types = self._get_boosted_types(query)

        # 3. Re-Ranking
        scored_memories = []
        current_time = datetime.now()

        for i, memory_id in enumerate(results['ids'][0]):
            metadata = results['metadatas'][0][i]
            document = results['documents'][0][i]
            distance = results['distances'][0][i]

            # Vector Similarity (distance â†’ similarity)
            vector_similarity = 1.0 - distance

            # Recency (ìµœê·¼ì¼ìˆ˜ë¡ ë†’ìŒ)
            timestamp = datetime.fromisoformat(metadata['timestamp'])
            days_ago = (current_time - timestamp).days
            recency = 1.0 / (1.0 + days_ago / 30.0)  # 30ì¼ ê¸°ì¤€

            # Confidence (ë©”íƒ€ë°ì´í„°ì—ì„œ)
            confidence = metadata['confidence']

            # Type Boost (+15% if matching)
            memory_type = MemoryType(metadata['memory_type'])
            type_boost = 0.15 if memory_type in boosted_types else 0.0

            # Subject Match (+10% if exact match)
            subject_match = 0.10 if subject and metadata['subject'] == subject.value else 0.0

            # Urgency (D-day ê¸°ë°˜, ê¸´ê¸‰í• ìˆ˜ë¡ ë†’ìŒ)
            urgency = 1.0 - (days_until_exam / 100.0)
            urgency = max(0.0, min(1.0, urgency))

            # Final Score
            final_score = (
                vector_similarity * 0.45
                + recency * 0.10
                + confidence * 0.10
                + type_boost
                + subject_match
                + urgency * 0.10
            )

            scored_memories.append({
                "id": memory_id,
                "content": document,
                "metadata": metadata,
                "score": final_score,
                "breakdown": {
                    "vector_similarity": vector_similarity,
                    "recency": recency,
                    "confidence": confidence,
                    "type_boost": type_boost,
                    "subject_match": subject_match,
                    "urgency": urgency,
                }
            })

        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        scored_memories.sort(key=lambda x: x['score'], reverse=True)

        print(f"ğŸ” [Retrieve] Found {len(scored_memories)} memories, returning top {top_k}")
        return scored_memories[:top_k]

    def _get_boosted_types(self, query: str) -> List[MemoryType]:
        """ì¿¼ë¦¬ì—ì„œ ë¶€ìŠ¤íŠ¸í•  ë©”ëª¨ë¦¬ ìœ í˜• ì¶”ì¶œ"""
        query_lower = query.lower()
        boosted = []

        for keyword, types in self.TYPE_BOOST_KEYWORDS.items():
            if keyword in query_lower:
                boosted.extend(types)

        return list(set(boosted))  # ì¤‘ë³µ ì œê±°

    def update_for_spaced_repetition(
        self,
        memory_id: str,
        quality: int,
        easiness_factor: float,
        interval: int
    ):
        """
        Spaced Repetition ì—…ë°ì´íŠ¸

        Args:
            memory_id: ë©”ëª¨ë¦¬ ID
            quality: ë³µìŠµ í’ˆì§ˆ (0-5)
            easiness_factor: SM-2 ë‚œì´ë„ ê³„ìˆ˜
            interval: ë‹¤ìŒ ë³µìŠµ ê°„ê²© (ì¼)
        """
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        existing = self.collection.get(ids=[memory_id])
        if not existing['ids']:
            return

        metadata = existing['metadatas'][0]
        metadata['review_count'] = metadata.get('review_count', 0) + 1
        metadata['easiness_factor'] = easiness_factor
        metadata['next_review_date'] = (datetime.now() + timedelta(days=interval)).isoformat()

        # ChromaDB ì—…ë°ì´íŠ¸
        self.collection.update(
            ids=[memory_id],
            metadatas=[metadata]
        )

        print(f"ğŸ”„ [SR] Updated: {memory_id}, next review in {interval} days")

    def get_statistics(self) -> Dict:
        """ë©”ëª¨ë¦¬ í†µê³„"""
        all_memories = self.collection.get()

        if not all_memories['ids']:
            return {"total": 0}

        stats = {
            "total": len(all_memories['ids']),
            "by_type": {},
            "by_subject": {},
            "avg_mastery": 0.0,
        }

        mastery_sum = 0
        for metadata in all_memories['metadatas']:
            # By type
            mem_type = metadata['memory_type']
            stats['by_type'][mem_type] = stats['by_type'].get(mem_type, 0) + 1

            # By subject
            subject = metadata['subject']
            stats['by_subject'][subject] = stats['by_subject'].get(subject, 0) + 1

            # Mastery
            mastery_sum += metadata.get('mastery_level', 0)

        stats['avg_mastery'] = mastery_sum / len(all_memories['ids'])

        return stats
```

---

## 2. Subject-Aware Router (ê³¼ëª©ë³„ ìŠ¤ë§ˆíŠ¸ ë¼ìš°í„°)

### íŒŒì¼: `core/router.py`

```python
"""
Subject-Aware Router - ê³¼ëª© ê°ì§€ + ë³µì¡ë„ ê¸°ë°˜ ë¼ìš°íŒ…

ACE V5.2 ê¸°ë³¸ Router í™•ì¥:
- ê³¼ëª© ìë™ ê°ì§€ (êµ­ì–´/ìˆ˜í•™/ì˜ì–´/ê³¼íƒ/ì‚¬íƒ)
- ê³¼ëª©ë³„ ë³µì¡ë„ í‚¤ì›Œë“œ
- ê°ì • ìƒíƒœ ì²´í¬ (ìŠ¤íŠ¸ë ˆìŠ¤/ë¶ˆì•ˆ â†’ ì‹¬ë¦¬ ì§€ì› ëª¨ë“œ)
"""

from enum import Enum
from dataclasses import dataclass
from typing import Optional, Dict
import re


class RouteDecision(Enum):
    """ë¼ìš°íŒ… ê²°ì •"""
    SIMPLE = "simple"      # â†’ GPT-5-nano
    MEDIUM = "medium"      # â†’ GPT-5-mini
    COMPLEX = "complex"    # â†’ GPT-5.2
    VISION = "vision"      # â†’ Gemini-3-flash
    PSYCHOLOGY = "psychology"  # â†’ ì‹¬ë¦¬ ì§€ì› ëª¨ë“œ


class SubjectType(Enum):
    """ê³¼ëª© ìœ í˜•"""
    KOREAN = "korean"
    MATH = "math"
    ENGLISH = "english"
    SCIENCE = "science"
    SOCIAL = "social"
    GENERAL = "general"


@dataclass
class RoutingContext:
    """ë¼ìš°íŒ… ì»¨í…ìŠ¤íŠ¸"""
    decision: RouteDecision
    subject: SubjectType
    complexity_score: float
    emotion_detected: Optional[str] = None
    matched_keywords: Dict[str, float] = None


class SubjectAwareRouter:
    """
    ê³¼ëª© ì¸ì‹ + ë³µì¡ë„ ê¸°ë°˜ ë¼ìš°í„°

    Process:
    1. ì´ë¯¸ì§€ ê°ì§€ â†’ VISION
    2. ê°ì • í‚¤ì›Œë“œ ê°ì§€ â†’ PSYCHOLOGY
    3. ê³¼ëª© ê°ì§€ (êµ­/ì˜/ìˆ˜/ê³¼/ì‚¬)
    4. ë³µì¡ë„ ê³„ì‚° (ê³¼ëª©ë³„ í‚¤ì›Œë“œ + ê¸°ë³¸ í‚¤ì›Œë“œ)
    5. Threshold ê¸°ë°˜ ëª¨ë¸ ì„ íƒ
    """

    # ê³¼ëª© ê°ì§€ í‚¤ì›Œë“œ
    SUBJECT_KEYWORDS = {
        SubjectType.KOREAN: ["êµ­ì–´", "ë¹„ë¬¸í•™", "ë¬¸í•™", "ë¬¸ë²•", "í™”ë²•", "ì‘ë¬¸", "ì–¸ë§¤", "ë…ì„œ"],
        SubjectType.MATH: ["ìˆ˜í•™", "ë¯¸ì ë¶„", "í™•ë¥ ", "í†µê³„", "ê¸°í•˜", "í•¨ìˆ˜", "ë¯¸ë¶„", "ì ë¶„"],
        SubjectType.ENGLISH: ["ì˜ì–´", "ë¹ˆì¹¸", "ìˆœì„œ", "ìš”ì•½", "ë¬¸ë²•", "ì–´íœ˜", "ë…í•´", "ë“£ê¸°"],
        SubjectType.SCIENCE: ["ê³¼í•™", "ë¬¼ë¦¬", "í™”í•™", "ìƒëª…", "ì§€êµ¬ê³¼í•™", "ê³¼íƒ"],
        SubjectType.SOCIAL: ["ì‚¬íšŒ", "ê²½ì œ", "ìœ¤ë¦¬", "ì§€ë¦¬", "ì—­ì‚¬", "ì‚¬íƒ", "ì‚¬íšŒë¬¸í™”"],
    }

    # ê³¼ëª©ë³„ ë³µì¡ë„ í‚¤ì›Œë“œ
    SUBJECT_COMPLEXITY_KEYWORDS = {
        # êµ­ì–´
        "ë¹„ë¬¸í•™": 0.30, "ë¬¸í•™": 0.25, "ë¬¸ë²•": 0.28, "í™”ë²•": 0.22,
        "ì§€ë¬¸": 0.20, "ì„ ì§€": 0.15, "ì£¼ì œ": 0.18, "ìš”ì§€": 0.18,

        # ìˆ˜í•™
        "ë¯¸ì ë¶„": 0.40, "í™•ë¥ ": 0.35, "ê¸°í•˜": 0.38, "ì¦ëª…": 0.35,
        "ê³„ì‚°": 0.20, "ê³µì‹": 0.15, "í•¨ìˆ˜": 0.25, "ê·¸ë˜í”„": 0.22,

        # ì˜ì–´
        "ë¹ˆì¹¸": 0.30, "ìˆœì„œ": 0.28, "ìš”ì•½": 0.25, "ë¬¸ë²•": 0.22,
        "ë…í•´": 0.20, "ë“£ê¸°": 0.10, "ì–´íœ˜": 0.15,

        # ê³¼í•™/ì‚¬íšŒ
        "ì‹¤í—˜": 0.25, "ê°œë…": 0.18, "ê·¸ë˜í”„": 0.22, "ë¶„ì„": 0.28,
    }

    # ê¸°ë³¸ ë³µì¡ë„ í‚¤ì›Œë“œ (ACE V5.2 ê¸°ë³¸)
    GENERAL_COMPLEXITY_KEYWORDS = {
        # High (0.25+)
        "implement": 0.35, "ì„¤ê³„": 0.35, "ì•„í‚¤í…ì²˜": 0.40,
        "ë¶„ì„": 0.30, "ìµœì í™”": 0.30, "ë³µì¡": 0.35,
        # Medium (0.15-0.24)
        "create": 0.20, "ë§Œë“¤ì–´": 0.20, "ì„¤ëª…": 0.15,
        "update": 0.18, "ìˆ˜ì •": 0.18,
        # Low (0-0.14)
        "hello": 0.05, "ì•ˆë…•": 0.05, "what": 0.10,
    }

    # ê°ì • í‚¤ì›Œë“œ (ì‹¬ë¦¬ ì§€ì› ëª¨ë“œ íŠ¸ë¦¬ê±°)
    EMOTION_KEYWORDS = {
        "ë¶ˆì•ˆ": "anxious", "ê¸´ì¥": "nervous", "ê±±ì •": "worried",
        "í˜ë“¤": "stressed", "í”¼ê³¤": "tired", "ì§€ì³": "exhausted",
        "í¬ê¸°": "giving_up", "ë¬´ì„œì›Œ": "scared", "ìŠ¬í””": "sad",
    }

    # Complexity Thresholds
    THRESHOLDS = {
        "simple": 0.3,   # < 0.3 â†’ SIMPLE
        "medium": 0.6,   # 0.3 ~ 0.6 â†’ MEDIUM
        # >= 0.6 â†’ COMPLEX
    }

    def route(
        self,
        task: str,
        has_image: bool = False
    ) -> RoutingContext:
        """
        ë¼ìš°íŒ… ê²°ì •

        Args:
            task: ì‚¬ìš©ì ì…ë ¥
            has_image: ì´ë¯¸ì§€ í¬í•¨ ì—¬ë¶€

        Returns:
            RoutingContext: ë¼ìš°íŒ… ê²°ì • + ì»¨í…ìŠ¤íŠ¸
        """
        # 1. ì´ë¯¸ì§€ ìš°ì„  ì²˜ë¦¬
        if has_image:
            return RoutingContext(
                decision=RouteDecision.VISION,
                subject=SubjectType.GENERAL,
                complexity_score=0.0,
            )

        # 2. ê°ì • í‚¤ì›Œë“œ ê°ì§€
        emotion = self._detect_emotion(task)
        if emotion:
            return RoutingContext(
                decision=RouteDecision.PSYCHOLOGY,
                subject=SubjectType.GENERAL,
                complexity_score=0.0,
                emotion_detected=emotion
            )

        # 3. ê³¼ëª© ê°ì§€
        subject = self._detect_subject(task)

        # 4. ë³µì¡ë„ ê³„ì‚°
        complexity_score, matched_keywords = self._calculate_complexity(task, subject)

        # 5. Threshold ê¸°ë°˜ ê²°ì •
        if complexity_score < self.THRESHOLDS["simple"]:
            decision = RouteDecision.SIMPLE
        elif complexity_score < self.THRESHOLDS["medium"]:
            decision = RouteDecision.MEDIUM
        else:
            decision = RouteDecision.COMPLEX

        return RoutingContext(
            decision=decision,
            subject=subject,
            complexity_score=complexity_score,
            matched_keywords=matched_keywords
        )

    def _detect_subject(self, task: str) -> SubjectType:
        """ê³¼ëª© ê°ì§€"""
        task_lower = task.lower()

        # ê³¼ëª©ë³„ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        scores = {}
        for subject, keywords in self.SUBJECT_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw in task_lower)
            if score > 0:
                scores[subject] = score

        # ìµœê³  ì ìˆ˜ ê³¼ëª© ë°˜í™˜
        if scores:
            return max(scores, key=scores.get)

        return SubjectType.GENERAL

    def _calculate_complexity(
        self,
        task: str,
        subject: SubjectType
    ) -> tuple[float, Dict[str, float]]:
        """
        ë³µì¡ë„ ê³„ì‚°

        Returns:
            (complexity_score, matched_keywords)
        """
        task_lower = task.lower()
        matched = {}

        # ê³¼ëª©ë³„ ë³µì¡ë„ í‚¤ì›Œë“œ
        for keyword, weight in self.SUBJECT_COMPLEXITY_KEYWORDS.items():
            if keyword in task_lower:
                matched[keyword] = weight

        # ê¸°ë³¸ ë³µì¡ë„ í‚¤ì›Œë“œ
        for keyword, weight in self.GENERAL_COMPLEXITY_KEYWORDS.items():
            if keyword in task_lower:
                matched[keyword] = weight

        # í‰ê·  ë³µì¡ë„
        if matched:
            complexity_score = sum(matched.values()) / len(matched)
        else:
            complexity_score = 0.1  # ê¸°ë³¸ê°’

        return complexity_score, matched

    def _detect_emotion(self, task: str) -> Optional[str]:
        """ê°ì • í‚¤ì›Œë“œ ê°ì§€"""
        task_lower = task.lower()

        for keyword, emotion in self.EMOTION_KEYWORDS.items():
            if keyword in task_lower:
                return emotion

        return None
```

---

## 3. Stress Monitor (ì‹¬ë¦¬ ì§€ì› ì‹œìŠ¤í…œ)

### íŒŒì¼: `core/stress_monitor.py`

```python
"""
Stress Monitor - ìŠ¤íŠ¸ë ˆìŠ¤ & ë²ˆì•„ì›ƒ ê°ì§€ ì‹œìŠ¤í…œ

Features:
- ê°ì • ìƒíƒœ ë¶„ì„ (í…ìŠ¤íŠ¸ â†’ ê°ì • ì ìˆ˜)
- ë²ˆì•„ì›ƒ ë ˆë²¨ ê°ì§€ (ìµœê·¼ 7ì¼ í•™ìŠµ ë°ì´í„° ë¶„ì„)
- ì‹¬ë¦¬ ì§€ì› ë©”ì‹œì§€ ìƒì„±
"""

from enum import Enum
from dataclasses import dataclass
from typing import List, Dict
from datetime import datetime, timedelta


class EmotionType(Enum):
    """ê°ì • ìœ í˜•"""
    NEUTRAL = "neutral"          # ì¤‘ë¦½
    STRESSED = "stressed"        # ìŠ¤íŠ¸ë ˆìŠ¤
    ANXIOUS = "anxious"          # ë¶ˆì•ˆ
    MOTIVATED = "motivated"      # ë™ê¸°ë¶€ì—¬ë¨
    FRUSTRATED = "frustrated"    # ì¢Œì ˆ
    TIRED = "tired"              # í”¼ê³¤
    CONFIDENT = "confident"      # ìì‹ ê°


class BurnoutLevel(Enum):
    """ë²ˆì•„ì›ƒ ë ˆë²¨"""
    LOW = "low"          # ì •ìƒ
    MEDIUM = "medium"    # ì£¼ì˜ í•„ìš”
    HIGH = "high"        # ê¸´ê¸‰ íœ´ì‹ í•„ìš”


@dataclass
class StudySession:
    """í•™ìŠµ ì„¸ì…˜"""
    timestamp: datetime
    duration_minutes: int        # í•™ìŠµ ì‹œê°„ (ë¶„)
    emotion: EmotionType         # ê°ì • ìƒíƒœ
    efficiency_score: float      # íš¨ìœ¨ì„± (0-1)
    score_improvement: float     # ì„±ì  ë³€í™”


class StressMonitor:
    """
    ìŠ¤íŠ¸ë ˆìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

    Features:
    - ì‹¤ì‹œê°„ ê°ì • ë¶„ì„
    - ë²ˆì•„ì›ƒ ê°ì§€ (7ì¼ ë°ì´í„° ê¸°ë°˜)
    - ì‹¬ë¦¬ ì§€ì› ë©”ì‹œì§€ ì¶”ì²œ
    """

    # ê°ì • í‚¤ì›Œë“œì™€ ì ìˆ˜
    STRESS_KEYWORDS = {
        "ë¶ˆì•ˆ": 0.8, "ê¸´ì¥": 0.7, "ê±±ì •": 0.6,
        "í˜ë“¤": 0.7, "í”¼ê³¤": 0.5, "ì§€ì³": 0.8,
        "í¬ê¸°": 0.9, "ì•ˆë¼": 0.7, "ë¬´ì„œì›Œ": 0.8,
        "ë‘ë ¤": 0.7, "ìŠ¬í””": 0.6, "ì™¸ë¡œ": 0.5,
    }

    MOTIVATION_KEYWORDS = {
        "ì˜í•˜ê³ ì‹¶ì–´": 0.7, "ì—´ì‹¬íˆ": 0.6, "í•´ë‚¼": 0.8,
        "ëª©í‘œ": 0.5, "í™”ì´íŒ…": 0.6, "ë„ì „": 0.7,
        "ìì‹ ": 0.6, "í• ìˆ˜ìˆ": 0.7, "ë…¸ë ¥": 0.5,
    }

    # ë²ˆì•„ì›ƒ ì„ê³„ê°’
    BURNOUT_THRESHOLDS = {
        "avg_study_hours": 4.0,       # í‰ê·  4ì‹œê°„ ì´ìƒ
        "negative_emotion_ratio": 0.6, # ë¶€ì • ê°ì • 60% ì´ìƒ
        "efficiency_threshold": 0.5,   # íš¨ìœ¨ì„± 50% ë¯¸ë§Œ
    }

    def __init__(self):
        self.sessions: List[StudySession] = []

    def analyze_emotion(self, text: str) -> tuple[EmotionType, float]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ë¶„ì„

        Args:
            text: ì‚¬ìš©ì ì…ë ¥

        Returns:
            (emotion_type, emotion_score)
        """
        text_lower = text.lower()

        # ìŠ¤íŠ¸ë ˆìŠ¤ ì ìˆ˜ ê³„ì‚°
        stress_score = 0.0
        stress_matches = 0
        for keyword, score in self.STRESS_KEYWORDS.items():
            if keyword in text_lower:
                stress_score += score
                stress_matches += 1

        # ë™ê¸°ë¶€ì—¬ ì ìˆ˜ ê³„ì‚°
        motivation_score = 0.0
        motivation_matches = 0
        for keyword, score in self.MOTIVATION_KEYWORDS.items():
            if keyword in text_lower:
                motivation_score += score
                motivation_matches += 1

        # ê°ì • ê²°ì •
        if stress_matches == 0 and motivation_matches == 0:
            return EmotionType.NEUTRAL, 0.0

        if stress_matches > motivation_matches:
            avg_stress = stress_score / stress_matches
            if avg_stress >= 0.7:
                emotion = EmotionType.ANXIOUS if "ë¶ˆì•ˆ" in text_lower or "ê¸´ì¥" in text_lower else EmotionType.STRESSED
            elif avg_stress >= 0.5:
                emotion = EmotionType.TIRED
            else:
                emotion = EmotionType.FRUSTRATED

            return emotion, avg_stress

        else:
            avg_motivation = motivation_score / motivation_matches
            if avg_motivation >= 0.6:
                emotion = EmotionType.MOTIVATED
            else:
                emotion = EmotionType.CONFIDENT

            return emotion, avg_motivation

    def detect_burnout(
        self,
        recent_days: int = 7
    ) -> tuple[BurnoutLevel, Dict[str, float]]:
        """
        ë²ˆì•„ì›ƒ ê°ì§€ (ìµœê·¼ Nì¼ ë°ì´í„° ë¶„ì„)

        Args:
            recent_days: ë¶„ì„í•  ìµœê·¼ ì¼ìˆ˜

        Returns:
            (burnout_level, metrics)
        """
        # ìµœê·¼ Nì¼ ì„¸ì…˜ í•„í„°ë§
        cutoff_date = datetime.now() - timedelta(days=recent_days)
        recent_sessions = [
            s for s in self.sessions
            if s.timestamp >= cutoff_date
        ]

        if len(recent_sessions) == 0:
            return BurnoutLevel.LOW, {}

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        total_minutes = sum(s.duration_minutes for s in recent_sessions)
        avg_study_hours = (total_minutes / 60) / recent_days

        negative_emotions = [
            EmotionType.STRESSED,
            EmotionType.ANXIOUS,
            EmotionType.FRUSTRATED,
            EmotionType.TIRED
        ]
        negative_count = sum(1 for s in recent_sessions if s.emotion in negative_emotions)
        negative_emotion_ratio = negative_count / len(recent_sessions)

        avg_efficiency = sum(s.efficiency_score for s in recent_sessions) / len(recent_sessions)

        total_score_change = sum(s.score_improvement for s in recent_sessions)

        metrics = {
            "avg_study_hours": avg_study_hours,
            "negative_emotion_ratio": negative_emotion_ratio,
            "avg_efficiency": avg_efficiency,
            "score_improvement": total_score_change,
        }

        # ë²ˆì•„ì›ƒ ë ˆë²¨ ê²°ì •
        if (
            avg_study_hours >= self.BURNOUT_THRESHOLDS["avg_study_hours"]
            and negative_emotion_ratio >= self.BURNOUT_THRESHOLDS["negative_emotion_ratio"]
            and avg_efficiency < self.BURNOUT_THRESHOLDS["efficiency_threshold"]
        ):
            return BurnoutLevel.HIGH, metrics

        elif negative_emotion_ratio >= 0.4 or avg_efficiency < 0.6:
            return BurnoutLevel.MEDIUM, metrics

        else:
            return BurnoutLevel.LOW, metrics

    def get_support_message(
        self,
        emotion: EmotionType,
        burnout_level: BurnoutLevel
    ) -> str:
        """
        ì‹¬ë¦¬ ì§€ì› ë©”ì‹œì§€ ìƒì„±

        Args:
            emotion: í˜„ì¬ ê°ì •
            burnout_level: ë²ˆì•„ì›ƒ ë ˆë²¨

        Returns:
            support_message: ì§€ì› ë©”ì‹œì§€
        """
        messages = {
            # ê°ì •ë³„ ë©”ì‹œì§€
            EmotionType.ANXIOUS: [
                "ì‹œí—˜ ë¶ˆì•ˆì€ ëˆ„êµ¬ë‚˜ ëŠë¼ëŠ” ê°ì •ì´ì•¼. ê¹Šê²Œ ìˆ¨ì„ ì‰¬ê³ , ì§€ê¸ˆê¹Œì§€ ì˜ ì¤€ë¹„í•´ì˜¨ ê²ƒë“¤ì„ ë¯¿ì–´ë´!",
                "ê¸´ì¥ë  ë•ŒëŠ” 5ë¶„ë§Œ ì‰¬ë©´ì„œ ì¢‹ì•„í•˜ëŠ” ìŒì•…ì„ ë“¤ì–´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œ? ì‘ì€ íœ´ì‹ì´ í° ë„ì›€ì´ ë¼.",
            ],
            EmotionType.STRESSED: [
                "ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ëŠë¼ê³  ìˆêµ¬ë‚˜. ì˜¤ëŠ˜ì€ í•™ìŠµëŸ‰ì„ 20% ì¤„ì´ê³ , ê°€ë²¼ìš´ ì‚°ì±…ì„ í•´ë³´ëŠ” ê±´ ì–´ë•Œ?",
                "ë„ˆë¬´ ë¬´ë¦¬í•˜ì§€ ë§ˆ. ê¾¸ì¤€íˆ í•˜ëŠ” ê²ƒì´ í­ë°œì ìœ¼ë¡œ í•˜ëŠ” ê²ƒë³´ë‹¤ ë” íš¨ê³¼ì ì´ì•¼.",
            ],
            EmotionType.FRUSTRATED: [
                "ì¢Œì ˆê°ì´ ë“¤ ë•ŒëŠ” ì‘ì€ ì„±ê³µì„ ê²½í—˜í•˜ëŠ” ê²Œ ì¤‘ìš”í•´. ì‰¬ìš´ ë¬¸ì œë¶€í„° ë‹¤ì‹œ í’€ì–´ë³´ì!",
                "ì–´ë ¤ìš´ ì‹œê¸°ë¥¼ ê²ªê³  ìˆì§€ë§Œ, ì´ ë˜í•œ ì„±ì¥ì˜ ê³¼ì •ì´ì•¼. ì˜¤ëŠ˜ í•˜ë£¨ë§Œ ì§‘ì¤‘í•´ë³´ì.",
            ],
            EmotionType.TIRED: [
                "í”¼ê³¤í•  ë• ë¬´ë¦¬í•˜ì§€ ë§ê³  ì¶©ë¶„íˆ ì‰¬ì–´. 30ë¶„ë§Œ ìë„ ì»¨ë””ì…˜ì´ ë§ì´ ì¢‹ì•„ì§ˆ ê±°ì•¼.",
                "ì²´ë ¥ì´ ê³§ ì‹¤ë ¥ì´ì•¼. ì˜¤ëŠ˜ì€ ì¼ì° ìê³  ë‚´ì¼ ë‹¤ì‹œ ì‹œì‘í•˜ì!",
            ],
            EmotionType.MOTIVATED: [
                "ì¢‹ì€ ì—ë„ˆì§€ë„¤! ì´ ê¸°ì„¸ë¡œ ì˜¤ëŠ˜ ëª©í‘œë¥¼ ë‹¬ì„±í•´ë³´ì!",
                "ë™ê¸°ë¶€ì—¬ê°€ ì¶©ë§Œí•  ë•Œ ìµœëŒ€í•œ í™œìš©í•˜ë˜, ë²ˆì•„ì›ƒ ì£¼ì˜! ì ì ˆí•œ íœ´ì‹ë„ ìŠì§€ ë§ˆ.",
            ],
        }

        # ë²ˆì•„ì›ƒ ë ˆë²¨ë³„ ì¶”ê°€ ë©”ì‹œì§€
        burnout_messages = {
            BurnoutLevel.HIGH: "âš ï¸ ë²ˆì•„ì›ƒ ê²½ê³ ! ì˜¤ëŠ˜ì€ ì™„ì „íˆ ì‰¬ëŠ” ë‚ ë¡œ í•˜ì. ì¥ê¸°ì ìœ¼ë¡œ ë³´ë©´ ì´ê²Œ ë” ë„ì›€ì´ ë¼.",
            BurnoutLevel.MEDIUM: "ğŸ’› ì»¨ë””ì…˜ ê´€ë¦¬ í•„ìš”. ì˜¤ëŠ˜ í•™ìŠµ ì‹œê°„ì„ 20% ì¤„ì´ê³ , ì¢‹ì•„í•˜ëŠ” ê³¼ëª© ìœ„ì£¼ë¡œ ê³µë¶€í•´ë³´ì.",
            BurnoutLevel.LOW: "âœ… ì¢‹ì€ ì»¨ë””ì…˜! ê³„ì† ì´ í˜ì´ìŠ¤ë¡œ ê°€ì!",
        }

        # ë©”ì‹œì§€ ì¡°í•©
        emotion_msg = messages.get(emotion, ["í™”ì´íŒ…! ì˜¤ëŠ˜ë„ ì˜ í•´ë‚¼ ê±°ì•¼!"])[0]
        burnout_msg = burnout_messages[burnout_level]

        return f"{emotion_msg}\n\n{burnout_msg}"

    def log_session(
        self,
        duration_minutes: int,
        emotion: EmotionType,
        efficiency_score: float,
        score_improvement: float = 0.0
    ):
        """í•™ìŠµ ì„¸ì…˜ ê¸°ë¡"""
        session = StudySession(
            timestamp=datetime.now(),
            duration_minutes=duration_minutes,
            emotion=emotion,
            efficiency_score=efficiency_score,
            score_improvement=score_improvement
        )
        self.sessions.append(session)

        print(f"ğŸ“Š [Session] Logged: {duration_minutes}min, {emotion.value}, efficiency={efficiency_score:.2f}")
```

---

## 4. Spaced Repetition Engine (SM-2 ì•Œê³ ë¦¬ì¦˜)

### íŒŒì¼: `memory/spaced_repetition.py`

```python
"""
Spaced Repetition Engine - SM-2 ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ë³µìŠµ ìŠ¤ì¼€ì¤„ëŸ¬

SM-2 (SuperMemo 2): ì¥ê¸° ê¸°ì–µ í˜•ì„±ì„ ìœ„í•œ ìµœì  ë³µìŠµ ê°„ê²© ê³„ì‚°
"""

from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import List, Dict
import heapq


@dataclass
class ReviewItem:
    """ë³µìŠµ í•­ëª©"""
    id: str
    subject: str           # ê³¼ëª©
    topic: str             # ì£¼ì œ/ë‹¨ì›
    content: str           # ë‚´ìš©
    easiness_factor: float = 2.5    # ë‚œì´ë„ ê³„ìˆ˜ (1.3 ~ 2.5+)
    interval: int = 0                # ë³µìŠµ ê°„ê²© (ì¼)
    repetitions: int = 0             # ë³µìŠµ íšŸìˆ˜
    next_review_date: datetime = None
    mastery_level: int = 0          # ìˆ™ë‹¬ë„ (0-10)
    priority: float = 0.0           # ìš°ì„ ìˆœìœ„ ì ìˆ˜


class SpacedRepetitionEngine:
    """
    SM-2 ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ Spaced Repetition

    Features:
    - SM-2 ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìµœì  ë³µìŠµ ê°„ê²© ê³„ì‚°
    - ìš°ì„ ìˆœìœ„ íë¡œ ë³µìŠµ ìŠ¤ì¼€ì¤„ ê´€ë¦¬
    - ì·¨ì•½ì  ìš°ì„  ë³µìŠµ
    """

    def __init__(self):
        self.items: Dict[str, ReviewItem] = {}
        self.review_queue = []  # ìš°ì„ ìˆœìœ„ í (heapq)

    def add_item(
        self,
        item_id: str,
        subject: str,
        topic: str,
        content: str,
        initial_mastery: int = 0
    ):
        """ë³µìŠµ í•­ëª© ì¶”ê°€"""
        item = ReviewItem(
            id=item_id,
            subject=subject,
            topic=topic,
            content=content,
            next_review_date=datetime.now(),  # ì¦‰ì‹œ ë³µìŠµ
            mastery_level=initial_mastery
        )

        self.items[item_id] = item
        self._update_priority(item)
        heapq.heappush(self.review_queue, (item.priority, item_id))

        print(f"â• [SR] Added: {topic} ({subject})")

    def review_item(
        self,
        item_id: str,
        quality: int
    ) -> ReviewItem:
        """
        ë³µìŠµ ìˆ˜í–‰ ë° SM-2 ì•Œê³ ë¦¬ì¦˜ ì ìš©

        Args:
            item_id: ë³µìŠµ í•­ëª© ID
            quality: ë³µìŠµ í’ˆì§ˆ (0-5)
                - 5: ì™„ë²½ (perfect response)
                - 4: ì •í™•í•œ ì‘ë‹µ (ì•½ê°„ ë§ì„¤ì„)
                - 3: ì •í™•í•œ ì‘ë‹µ (ë§ì´ ë§ì„¤ì„)
                - 2: í‹€ë¦¼ (ì‰¬ìš´ ë³µìŠµ í›„ ê¸°ì–µë‚¨)
                - 1: í‹€ë¦¼ (ë³µìŠµ í›„ì—ë„ ì–´ë ¤ì›€)
                - 0: ì „í˜€ ê¸°ì–µ ì•ˆë‚¨

        Returns:
            updated_item: ì—…ë°ì´íŠ¸ëœ í•­ëª©
        """
        if item_id not in self.items:
            raise ValueError(f"Item not found: {item_id}")

        item = self.items[item_id]

        # SM-2 ì•Œê³ ë¦¬ì¦˜ ì ìš©
        new_ef, new_interval = self._calculate_sm2(
            item.easiness_factor,
            item.interval,
            item.repetitions,
            quality
        )

        # í•­ëª© ì—…ë°ì´íŠ¸
        item.easiness_factor = new_ef
        item.interval = new_interval
        item.repetitions += 1
        item.next_review_date = datetime.now() + timedelta(days=new_interval)

        # ìˆ™ë‹¬ë„ ì—…ë°ì´íŠ¸ (quality ê¸°ë°˜)
        mastery_change = (quality - 3) * 0.5  # -1.5 ~ +1.0
        item.mastery_level = max(0, min(10, item.mastery_level + mastery_change))

        # ìš°ì„ ìˆœìœ„ ì¬ê³„ì‚°
        self._update_priority(item)

        print(f"âœ… [SR] Reviewed: {item.topic}, quality={quality}, next in {new_interval} days")
        return item

    def _calculate_sm2(
        self,
        ef: float,
        interval: int,
        repetitions: int,
        quality: int
    ) -> tuple[float, int]:
        """
        SM-2 ì•Œê³ ë¦¬ì¦˜ í•µì‹¬ ê³„ì‚°

        Returns:
            (new_easiness_factor, new_interval)
        """
        # Easiness Factor ì—…ë°ì´íŠ¸
        new_ef = ef + (0.1 - (5 - quality) * (0.08 + (5 - quality) * 0.02))

        # EF ìµœì†Œê°’ ì œí•œ
        if new_ef < 1.3:
            new_ef = 1.3

        # Interval ê³„ì‚°
        if quality < 3:
            # í‹€ë¦¼ â†’ 1ì¼ í›„ ë‹¤ì‹œ ë³µìŠµ
            new_interval = 1
            new_repetitions = 0
        else:
            if repetitions == 0:
                new_interval = 1
            elif repetitions == 1:
                new_interval = 6
            else:
                new_interval = int(interval * new_ef)

            new_repetitions = repetitions + 1

        return new_ef, new_interval

    def _update_priority(self, item: ReviewItem):
        """
        ë³µìŠµ ìš°ì„ ìˆœìœ„ ê³„ì‚°

        Priority = (10 - mastery_level) * 0.4  # ë‚®ì€ ìˆ™ë‹¬ë„ ìš°ì„ 
                 + urgency * 0.3                # ì„ë°•í•œ ë³µìŠµ ìš°ì„ 
                 + (1 / easiness_factor) * 0.2  # ì–´ë ¤ìš´ í•­ëª© ìš°ì„ 
                 + repetition_boost * 0.1       # ë°˜ë³µ íšŸìˆ˜ ì ì„ìˆ˜ë¡ ìš°ì„ 
        """
        # ìˆ™ë‹¬ë„ (ë‚®ì„ìˆ˜ë¡ ë†’ì€ ìš°ì„ ìˆœìœ„)
        mastery_score = (10 - item.mastery_level) * 0.4

        # ê¸´ê¸‰ë„ (ë³µìŠµì¼ì´ ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ìš°ì„ ìˆœìœ„)
        if item.next_review_date:
            days_until_review = (item.next_review_date - datetime.now()).days
            urgency = 1.0 / (1.0 + days_until_review) if days_until_review >= 0 else 1.0
        else:
            urgency = 1.0

        urgency_score = urgency * 0.3

        # ë‚œì´ë„ (ì–´ë ¤ìš¸ìˆ˜ë¡ ë†’ì€ ìš°ì„ ìˆœìœ„)
        difficulty_score = (1.0 / item.easiness_factor) * 0.2

        # ë°˜ë³µ íšŸìˆ˜ (ì ì„ìˆ˜ë¡ ë†’ì€ ìš°ì„ ìˆœìœ„)
        repetition_boost = (1.0 / (1.0 + item.repetitions)) * 0.1

        item.priority = mastery_score + urgency_score + difficulty_score + repetition_boost

    def get_due_items(self, limit: int = 10) -> List[ReviewItem]:
        """
        ë³µìŠµ í•„ìš” í•­ëª© ê°€ì ¸ì˜¤ê¸° (ìš°ì„ ìˆœìœ„ ìˆœ)

        Args:
            limit: ìµœëŒ€ ê°œìˆ˜

        Returns:
            due_items: ë³µìŠµ ëŒ€ìƒ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        now = datetime.now()
        due_items = []

        # ìš°ì„ ìˆœìœ„ íì—ì„œ ë³µìŠµ í•„ìš” í•­ëª© ì¶”ì¶œ
        while self.review_queue and len(due_items) < limit:
            priority, item_id = heapq.heappop(self.review_queue)
            item = self.items[item_id]

            # ë³µìŠµì¼ì´ ì§€ë‚¬ê±°ë‚˜ ì˜¤ëŠ˜ì¸ ê²½ìš°
            if item.next_review_date <= now:
                due_items.append(item)

        # ìš°ì„ ìˆœìœ„ ì¬ì •ë ¬ (ë‹¤ìŒ ì¡°íšŒë¥¼ ìœ„í•´)
        self.review_queue = []
        for item in self.items.values():
            heapq.heappush(self.review_queue, (item.priority, item.id))

        return due_items

    def get_statistics(self) -> Dict:
        """í†µê³„ ì •ë³´"""
        if not self.items:
            return {"total": 0}

        total = len(self.items)
        avg_mastery = sum(item.mastery_level for item in self.items.values()) / total
        avg_ef = sum(item.easiness_factor for item in self.items.values()) / total

        # ê³¼ëª©ë³„ í†µê³„
        by_subject = {}
        for item in self.items.values():
            if item.subject not in by_subject:
                by_subject[item.subject] = {"count": 0, "avg_mastery": 0.0}

            by_subject[item.subject]["count"] += 1
            by_subject[item.subject]["avg_mastery"] += item.mastery_level

        for subject in by_subject:
            count = by_subject[subject]["count"]
            by_subject[subject]["avg_mastery"] /= count

        return {
            "total": total,
            "avg_mastery": avg_mastery,
            "avg_easiness_factor": avg_ef,
            "by_subject": by_subject,
        }
```

---

## ìš”ì•½

ì´ ë¬¸ì„œì—ì„œëŠ” ìˆ˜ëŠ¥ ACE ì—ì´ì „íŠ¸ì˜ 4ê°€ì§€ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„¸íˆ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤:

1. **Learning Memory Lane**: ACE V5.2ì˜ 6ê°€ì§€ ë©”ëª¨ë¦¬ ìœ í˜•ì„ 12ê°€ì§€ë¡œ í™•ì¥ (êµìœ¡ ë„ë©”ì¸)
2. **Subject-Aware Router**: ê³¼ëª© ê°ì§€ + ë³µì¡ë„ + ê°ì • ìƒíƒœ ê¸°ë°˜ ë¼ìš°íŒ…
3. **Stress Monitor**: ê°ì • ë¶„ì„ + ë²ˆì•„ì›ƒ ê°ì§€ + ì‹¬ë¦¬ ì§€ì›
4. **Spaced Repetition Engine**: SM-2 ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ìµœì  ë³µìŠµ ìŠ¤ì¼€ì¤„

ê° ì»´í¬ë„ŒíŠ¸ëŠ” ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•˜ë©´ì„œë„ ì„œë¡œ ê¸´ë°€í•˜ê²Œ í†µí•©ë˜ì–´ í•™ìƒì˜ í•™ìŠµ íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
